{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import svm\n",
    "from multiprocessing import Pool, cpu_count, active_children\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'GeneralData/A/train'\n",
    "test_path = 'GeneralData/A/test'\n",
    "train_files = []\n",
    "test_files = []\n",
    "new_dict = dict()\n",
    "stemmer = PorterStemmer()\n",
    "#chat_corpus = [['uid','msg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #stems = stem_tokens(tokens, stemmer)    ## <-- (optional ?)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_extractor(file):\n",
    "    chat_corpus = []\n",
    "    tmp_dict = dict()\n",
    "\n",
    "    f = open(file)\n",
    "    soup = BeautifulSoup(f, 'xml')\n",
    "\n",
    "    # data extraction\n",
    "    all_post = soup.findAll('POST')\n",
    "    for post in all_post:\n",
    "        tmp = []\n",
    "        #if post.USERNAME.string:\n",
    "        #    tmp.append(post.USERNAME.string)\n",
    "        if post.BODY.string:\n",
    "            tmp.append(post.BODY.string)\n",
    "            chat_corpus.append(tmp)\n",
    "            \n",
    "    # data to string \n",
    "    text = ''\n",
    "            \n",
    "    for chats in chat_corpus:\n",
    "        #print(\"chats : ----\")\n",
    "        #print(chats)\n",
    "        for logs in chats:\n",
    "            tmp = ''\n",
    "            #print(\"logs : ----\")\n",
    "            #print(logs)\n",
    "            for pcs in logs:\n",
    "                tmp = tmp + pcs\n",
    "                tmp = tmp + \" : \"\n",
    "            text = text + tmp + \" \\n \"\n",
    "                    \n",
    "    lowers = text.lower()\n",
    "    no_punctuation = lowers.translate(string.punctuation)\n",
    "    tmp_dict[file] = no_punctuation\n",
    "    return tmp_dict\n",
    "\n",
    "def get_filenames(path):\n",
    "    list_of_files = []\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_path = subdir + os.path.sep + file\n",
    "            list_of_files.append(file_path)\n",
    "    return list_of_files\n",
    "\n",
    "def cb(data):\n",
    "    if data:\n",
    "        global new_dict\n",
    "        new_dict.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      " [*] Finished processing training data. Time taken : 2.53 sec\n",
      " [*] Feature Enginnering...\n",
      " [*] Completed. Time taken : 3.72 sec\n",
      "Processing testing data...\n",
      " [*] Finished processing testing data. Time taken : 3.02 sec\n",
      " [*] Feature Engineering...\n",
      " [*] Completed. Time taken : 4.22 sec\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(processes=cpu_count()*4, maxtasksperchild=25)\n",
    "    \n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    " \n",
    "train_files = get_filenames(train_path)\n",
    "test_files = get_filenames(test_path)\n",
    "\n",
    "### Block 1\n",
    "\n",
    "print(\"Processing training data...\")\n",
    "then = time()\n",
    "for file in train_files:\n",
    "    pool.apply_async(data_extractor, (file,), callback=cb)\n",
    "pool.close()\n",
    "while len(active_children()) > 1:\n",
    "    sleep(0.5)\n",
    "pool.join()\n",
    "now = time()\n",
    "print(\" [*] Finished processing training data. Time taken : %0.2f sec\" % (now - then))\n",
    "\n",
    "### Block 2\n",
    "\n",
    "print(\" [*] Feature Enginnering...\")\n",
    "then = time()\n",
    "train_tfidf = tfidf.fit_transform(new_dict.values())\n",
    "now = time()\n",
    "print(\" [*] Completed. Time taken : %0.2f sec\" % (now - then))\n",
    "new_dict.clear()\n",
    "\n",
    "  \n",
    "pool = Pool(processes=cpu_count()*4, maxtasksperchild=25)\n",
    "\n",
    "### Block 3\n",
    "\n",
    "print(\"Processing testing data...\")\n",
    "then = time()\n",
    "for file in test_files:\n",
    "    pool.apply_async(data_extractor, (file,), callback=cb)\n",
    "pool.close()\n",
    "while len(active_children()) > 1:\n",
    "    sleep(0.5)\n",
    "pool.join()\n",
    "now = time()\n",
    "print(\" [*] Finished processing testing data. Time taken : %0.2f sec\" % (now - then))\n",
    "    \n",
    "### Block 4\n",
    "\n",
    "print(\" [*] Feature Engineering...\")\n",
    "then = time()\n",
    "test_tfidf = tfidf.transform(new_dict.values())\n",
    "now = time()\n",
    "print(\" [*] Completed. Time taken : %0.2f sec\" % (now - then))\n",
    "new_dict.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting classifier...\n",
      "Using OneClassSVM\n",
      " [*] Training the classifier...\n",
      " [*] Training completed. Time taken : 0.003159 sec\n",
      "Prediciting results for training dataset...\n",
      "Prediciting results for test dataset...\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "### Block 5\n",
    "\n",
    "print(\"Starting classifier...\")\n",
    "print(\"Using OneClassSVM\")\n",
    "clf = svm.OneClassSVM(kernel='poly', degree=5, random_state=0)\n",
    "print(\" [*] Training the classifier...\")\n",
    "then = time()\n",
    "clf.fit(train_tfidf)\n",
    "now = time()\n",
    "print(\" [*] Training completed. Time taken : %0.6f sec\" % (now - then))\n",
    "print(\"Prediciting results for training dataset...\")\n",
    "y_pred_train = clf.predict(train_tfidf)\n",
    "print(\"Prediciting results for test dataset...\")\n",
    "y_pred_test = clf.predict(test_tfidf)\n",
    "print(\"Completed.\")\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 54.05 %\n",
      "Test accuracy : 57.89 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: %0.2f\" % (100-((n_error_train/y_pred_train.size)*100)), \"%\")\n",
    "print(\"Test accuracy : %0.2f\" % (100-((n_error_test/y_pred_test.size)*100)), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Results\n",
    "----\n",
    "#### Kernel : poly\n",
    " \n",
    "  | Deg | Tr | Te |\n",
    "  |:---:|:--:|:--:|\n",
    "  | 1 | 27.0% | 31.5% |\n",
    "  | 2 | 37.8% | 36.8% |\n",
    "  | 3 | \" | \" |\n",
    "  | 4 | 35.1% | \" |\n",
    "  | 5 | \" | \" |\n",
    "  | 6 | \" | \" |\n",
    "  | 7 | 37.8% | 36.8% |\n",
    "  | 8 | \" | \" |\n",
    "  | 9 | \" | \" |\n",
    "  | 10 | 35.1 | 36.8 |\n",
    "  | 11 | \" | \" |\n",
    "  | 12 | 37.8 | 36.8 |\n",
    "  | 24 | 18.9 | 21.0 |\n",
    "  | 25 | 94.5 | 94.7 |\n",
    "  | 26 | 100 | 100 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x62 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 49 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method csr_matrix.tocsr of <37x62 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1667 stored elements in Compressed Sparse Row format>>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "def class_report(conf_mat):\n",
    "    tp, fp, fn, tn = conf_mat.flatten()\n",
    "    measures = {}\n",
    "    measures['accuracy'] = (tp + tn) / (tp + fp + fn + tn)\n",
    "    measures['specificity'] = tn / (tn + fp)        # (true negative rate)\n",
    "    measures['sensitivity'] = tp / (tp + fn)        # (recall, true pos rate)\n",
    "    measures['precision'] = tp / (tp + fp)\n",
    "    measures['f1score'] = 2*tp / (2*tp + fp + fn)\n",
    "    return measures\n",
    "\n",
    "def analyze_model(model=None, folds=10):\n",
    "    ''' Run x-validation and return scores, averaged confusion matrix,\n",
    "        and df with false positives and negatives '''\n",
    "\n",
    "    X, y, X_test = load()\n",
    "    y = y.values   # to numpy\n",
    "    X = X.values\n",
    "    if not model:\n",
    "        model = load_model()\n",
    "\n",
    "    # Manual x-validation to accumulate actual\n",
    "    cv_skf = StratifiedKFold(y, n_folds=folds, shuffle=False, random_state=0)\n",
    "    scores = []\n",
    "    conf_mat = np.zeros((2, 2))      # Binary classification\n",
    "    false_pos = Set()\n",
    "    false_neg = Set()\n",
    "\n",
    "    for train_i, val_i in cv_skf:\n",
    "        X_train, X_val = X[train_i], X[val_i]\n",
    "        y_train, y_val = y[train_i], y[val_i]\n",
    "\n",
    "        print \"Fitting fold...\"\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print \"Predicting fold...\"\n",
    "        y_pprobs = model.predict_proba(X_val)       # Predicted probabilities\n",
    "        y_plabs = np.squeeze(model.predict(X_val))  # Predicted class labels\n",
    "\n",
    "        scores.append(roc_auc_score(y_val, y_pprobs[:, 1]))\n",
    "        confusion = confusion_matrix(y_val, y_plabs)\n",
    "        conf_mat += confusion\n",
    "\n",
    "        # Collect indices of false positive and negatives\n",
    "        fp_i = np.where((y_plabs==1) & (y_val==0))[0]\n",
    "        fn_i = np.where((y_plabs==0) & (y_val==1))[0]\n",
    "        false_pos.update(val_i[fp_i])\n",
    "        false_neg.update(val_i[fn_i])\n",
    "\n",
    "        print \"Fold score: \", scores[-1]\n",
    "        print \"Fold CM: \\n\", confusion\n",
    "\n",
    "    print \"\\nMean score: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2)\n",
    "    conf_mat /= folds\n",
    "    print \"Mean CM: \\n\", conf_mat\n",
    "    print \"\\nMean classification measures: \\n\"\n",
    "    print(class_report(conf_mat))\n",
    "    return scores, conf_mat, {'fp': sorted(false_pos), 'fn': sorted(false_neg)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Results [Testing dataset = 25% Training dataset]\n",
    "-----\n",
    "\n",
    "### *  (w/o stemming)\n",
    "\n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 83.9% | 71.4% | **<-- Best**\n",
    " | 2 | 75.0% | 64.2% |\n",
    " | 3 | 75.0% | 64.2% |\n",
    " | 4 | 64.2% | 64.2% |\n",
    " | 5 | 66.1% | 64.2% |\n",
    " | 6 | 75.0% | 71.4% |\n",
    " | **Mean** | **73.2%** | **66.6%** |\n",
    "\n",
    "### *  (w/ stemming)\n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 76.78% | 71.42% |\n",
    " | 2 | 62.50% | 57.14% |\n",
    " | 3 | 58.93% | 64.28% | \n",
    " | 4 | 60.71% | 57.14% |\n",
    " | 5 | 64.28% | 64.28% |\n",
    " | 6 | 80.35% | 71.43% | **<-- Best**\n",
    " | **Mean** | **67.25%** | **64.28%** |\n",
    " \n",
    " ### *  (w/o stemming & training with only predator chats)\n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 67.8% | 85.7% |\n",
    " | 2 | 60.7% | 78.5% |\n",
    " | 3 | 71.4% | 92.8% |\n",
    " | 4 | 76.7% | 92.8% | **<-- Best**\n",
    " | 5 | 75.0% | 92.8% |\n",
    " | 6 | 71.4% | 92.8% |\n",
    " | **Mean** | **70.5%** | **89.23%**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accuracy Results [3 fold cross-validation]\n",
    "-----\n",
    "\n",
    " ### *  (w/o stemming & training with only predator chats)\n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 13.5% | 36.8% |\n",
    " | 2 | 24.3% | 47.3% |\n",
    " | 3 | 59.4% | 78.9% | **<-- Best**\n",
    " | **Mean** | **32.4%** | **54.3%** |\n",
    " \n",
    " \n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 48.6% | 57.8% |\n",
    " | 2 | 67.5% | 89.4% | **<-- Best**\n",
    " | 3 | 56.7% | 63.1% |\n",
    " | **Mean** | **57.6%** | **70.1%** |\n",
    " \n",
    " \n",
    " | # | Training | Testing |\n",
    " |:-:|:--------:|:-------:|\n",
    " | 1 | 63.2% | 77.7% |\n",
    " | 2 | 78.9% | 83.3% | **<--Best**\n",
    " | 3 | 73.6% | 77.7% |\n",
    " | **Mean** | **71.9%** | **79.5%**|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
